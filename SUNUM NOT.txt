-CNNâ†’150Ã—150, Transfer Learning modelleriâ†’224Ã—224, 

1. GÃ¶rÃ¼ntÃ¼ boyutu, modelin giriÅŸ katmanÄ±na uygun olmalÄ±dÄ±r.

Yapay sinir aÄŸlarÄ±, sabit boyuttaki giriÅŸlerle Ã§alÄ±ÅŸÄ±r. Bu nedenle, eÄŸitim ve test verileri modelin gereksinimlerine gÃ¶re yeniden boyutlandÄ±rÄ±lÄ±r.

-Normalizasyon
-Piksel deÄŸerleri /255, preprocess_input() fonksiyonu,

GÃ¶rsel verilerde pikseller genellikle 0â€“255 aralÄ±ÄŸÄ±nda deÄŸer alÄ±r (8-bit).

Ancak bu deÄŸer aralÄ±ÄŸÄ± sinir aÄŸlarÄ± iÃ§in Ã§ok geniÅŸ olabilir. Bu yÃ¼zden Ã¶lÃ§eklendirme (normalizasyon) iÅŸlemi yapÄ±lÄ±r.

 1. Piksel DeÄŸerlerini 255'e BÃ¶lme (x / 255)
a. AmaÃ§: Verileri 0 ile 1 arasÄ±na Ã§ekerek modelin daha hÄ±zlÄ± ve kararlÄ± Ã¶ÄŸrenmesini saÄŸlamak.

b. KullanÄ±m: Ã–zellikle sÄ±fÄ±rdan oluÅŸturulan CNN modellerinde yaygÄ±n bir yÃ¶ntemdir.

c. FaydalarÄ±:

Modelin eÄŸitim sÃ¼resi kÄ±salÄ±r.

Aktivasyon fonksiyonlarÄ± (Ã¶rneÄŸin ReLU, sigmoid) daha verimli Ã§alÄ±ÅŸÄ±r.

AÅŸÄ±rÄ± bÃ¼yÃ¼k giriÅŸ deÄŸerlerinden kaynaklÄ± Ã¶ÄŸrenme problemleri azaltÄ±lÄ±r.

2. preprocess_input() Fonksiyonu
a. AmaÃ§: Transfer learning modelleri (VGG16, ResNet, MobileNet vb.) iÃ§in modelin beklentisine uygun ÅŸekilde giriÅŸ verisini normalize etmek.

b. YalnÄ±zca normalleÅŸtirme deÄŸil, ortalama Ã§Ä±karma veya kanal sÄ±ralama gibi iÅŸlemler de iÃ§erir.

c. Modelin eÄŸitildiÄŸi veriyle aynÄ± Ã¶lÃ§ekte ve yapÄ±da giriÅŸ verilmesini saÄŸlar.

d. KÃ¼tÃ¼phane Ã¶rneÄŸi:
from tensorflow.keras.applications.vgg16 import preprocess_input

Dikkat:
x/255 yerine preprocess_input() kullanmak transfer learning modellerinde daha doÄŸru sonuÃ§lar verir.


-Ã–znitelik Ã‡Ä±karÄ±mÄ±
-MobileNet son katman Ã¶zellikleri, 

Ã–znitelik (Feature) Ã‡Ä±karÄ±mÄ± Nedir?
GÃ¶rsellerden anlamlÄ±, ayÄ±rt edici bilgilerin Ã§Ä±karÄ±lmasÄ±dÄ±r.
Bu iÅŸlemde genellikle Ã¶nceden eÄŸitilmiÅŸ bir modelin alt katmanlarÄ± (Ã¶zellik Ã§Ä±karÄ±cÄ± katmanlarÄ±) kullanÄ±lÄ±r.

1. MobileNet ile Ã–znitelik Ã‡Ä±karÄ±mÄ±
a. MobileNet, dÃ¼ÅŸÃ¼k boyutlu ve hÄ±zlÄ± Ã§alÄ±ÅŸan bir transfer learning modelidir.

**b. EÄŸitimli aÄŸÄ±rlÄ±klar sayesinde gÃ¶rÃ¼ntÃ¼den Ã¶nemli desenleri (kenar, ÅŸekil, doku vb.) ayÄ±klayabilir.

c. Son katman (fully connected veya global average pooling katmanÄ± Ã¶ncesi) modelin Ã¶ÄŸrenilmiÅŸ en gÃ¼Ã§lÃ¼ Ã¶zniteliklerini taÅŸÄ±r.


 2. KullanÄ±m Åekli
MobileNetâ€™in sÄ±nÄ±flandÄ±rma katmanÄ± Ã§Ä±karÄ±lÄ±r (include_top=False).

GÃ¶rÃ¼ntÃ¼ modele verilir ve modelin son katmanÄ±ndan bir Ã¶znitelik vektÃ¶rÃ¼ (Ã¶rneÄŸin 1024 boyutlu) elde edilir.

Bu vektÃ¶r, daha sonra SVM, Random Forest gibi modellerde giriÅŸ olarak kullanÄ±lÄ±r.
 
3. AvantajlarÄ±
Derin Ã¶ÄŸrenme ile Ã§Ä±karÄ±lmÄ±ÅŸ zengin Ã¶zellikleri klasik makine Ã¶ÄŸrenmesi modelleriyle birleÅŸtirerek yÃ¼ksek doÄŸruluk saÄŸlar.

EÄŸitim sÃ¼resi Ã§ok kÄ±salÄ±r Ã§Ã¼nkÃ¼ model yeniden eÄŸitilmez, sadece Ã¶znitelik Ã§Ä±karÄ±mÄ± iÃ§in kullanÄ±lÄ±r.

DonanÄ±m dostu ve hÄ±zlÄ±dÄ±r (MobileNet bu iÅŸ iÃ§in idealdir).

-Veri BÃ¶lme
-%80 eÄŸitim / %20 test ayrÄ±mÄ±, 

Veri BÃ¶lme Nedir?
Elimizdeki veri seti, modelin Ã¶ÄŸrenmesi (eÄŸitim) ve deÄŸerlendirilmesi (test) amacÄ±yla ikiye ayrÄ±lÄ±r.

Bu, modelin sadece ezberlemesini deÄŸil, genelleme yeteneÄŸini test etmemizi saÄŸlar.


%80 EÄŸitim Verisi:

Model bu verilerle eÄŸitilir.

GiriÅŸ ve Ã§Ä±kÄ±ÅŸ Ã¶rnekleriyle model Ã¶rÃ¼ntÃ¼leri Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±r.

EÄŸitim sÃ¼recindeki aÄŸÄ±rlÄ±k gÃ¼ncellemeleri bu verilerle yapÄ±lÄ±r.

%20 Test Verisi:

Modelin gÃ¶rmediÄŸi verilerle performansÄ± deÄŸerlendirilir.

Modelin doÄŸruluk (accuracy), hassasiyet (precision), hata oranÄ± gibi metrikleri bu verilerle Ã¶lÃ§Ã¼lÃ¼r.


80/20 bÃ¶lÃ¼ÅŸÃ¼mÃ¼, dengeli bir yaklaÅŸÄ±m saÄŸlar:

Veri seti kÃ¼Ã§Ã¼kse, eÄŸitim iÃ§in yeterli veri bÄ±rakÄ±lÄ±r.

Test iÃ§in de yeterli Ã¶rnek kalÄ±r.

Daha bÃ¼yÃ¼k veri setlerinde farklÄ± oranlar da (Ã¶rneÄŸin 70/30, 90/10) kullanÄ±labilir.

-----------------------------------------------------------------------------------------------

-Conv2Dâ†’MaxPoolâ†’Flattenâ†’Dense,
1. Conv2D (Convolutional Katman)
AmaÃ§: GÃ¶rÃ¼ntÃ¼deki kenar, kÃ¶ÅŸe, doku gibi Ã¶znitelikleri tespit etmek.

NasÄ±l Ã‡alÄ±ÅŸÄ±r? KÃ¼Ã§Ã¼k filtreler (kernel) gÃ¶rÃ¼ntÃ¼ Ã¼zerinde gezdirilir ve Ã§arpÄ±m iÅŸlemleri yapÄ±lÄ±r.

SonuÃ§: GÃ¶rÃ¼ntÃ¼den Ã¶znitelik haritalarÄ± (feature maps) Ã§Ä±karÄ±lÄ±r.

ğŸ§© Benzetme: BÃ¼yÃ¼teÃ§le gÃ¶rseli tarayÄ±p Ã¶nemli desenleri bulmak gibi.


2. MaxPooling (Havuzlama KatmanÄ±)
AmaÃ§: Ã–zellik haritalarÄ±nÄ±n boyutunu kÃ¼Ã§Ã¼ltmek (downsampling) ve hesaplama yÃ¼kÃ¼nÃ¼ azaltmak.

NasÄ±l Ã‡alÄ±ÅŸÄ±r? Belirli bir bÃ¶lgedeki en bÃ¼yÃ¼k deÄŸeri seÃ§erek veri sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±r.

FaydasÄ±: Modelin daha az parametre ile daha hÄ±zlÄ± ve daha az overfitting riskiyle Ã¶ÄŸrenmesini saÄŸlar.

ğŸ§© Benzetme: BÃ¼yÃ¼k bir resmi Ã¶zetleyerek kÃ¼Ã§Ã¼k bir versiyonunu Ã§Ä±karmak gibi.

 3. Flatten (DÃ¼zleÅŸtirme KatmanÄ±)
AmaÃ§: 2D Ã¶znitelik haritalarÄ±nÄ±, tam baÄŸlÄ± (dense) katmana aktarabilmek iÃ§in tek boyutlu bir vektÃ¶re Ã§evirmek.

KullanÄ±m Yeri: CNN katmanlarÄ± ile dense katmanlar arasÄ±nda geÃ§iÅŸ yapar.

ğŸ§© Benzetme: Bir matrisin tÃ¼m elemanlarÄ±nÄ± sÄ±raya dizmek gibi.

 4. Dense (Tam BaÄŸlantÄ±lÄ± Katman)
AmaÃ§: Modelin sÄ±nÄ±flandÄ±rma kararÄ±nÄ± verdiÄŸi kÄ±sÄ±mdÄ±r.

Her nÃ¶ron, Ã¶nceki tÃ¼m nÃ¶ronlarla baÄŸlantÄ±lÄ±dÄ±r.

Genellikle son katmanda softmax/sigmoid aktivasyon ile sÄ±nÄ±f tahmini yapÄ±lÄ±r.

ğŸ§© Benzetme: Karar aÅŸamasÄ± â€“ tÃ¼m Ã¶ÄŸrenilen bilgilerin bir araya gelip sonuca varmasÄ±.


